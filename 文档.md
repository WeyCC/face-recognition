

该数据集的维度为（400，4096），内置400张人脸图片，每张图片将其延展特征数为4096，可以看到其维度之大。

数据需要进行降维的目的如下：

+ 在原始的高维空间中，包含冗余信息和噪声信息，会在实际应用中引入误差，影响准确率；而降维可以提取数据内部的本质结构，减少冗余信息和噪声信息造成的误差，提高应用中的精度。
+ 第二方面就是如果特征维度特别高，模型训练的时间过大，导致耗费资源，如果降低一些维度，这样可以在不降低过高的精度的前提下获得更高的性能

这里我们使用的是PCA降维，说白了就是主成分分析法，我们刚才说为了提高模型性能，需要将数据的维度进行缩减，但是我们肯定不能够直接减少数据的维度，因为这样会导致大幅度的丢失数据，进行降低模型精度。

出现这样的原因是没有考虑到现有数据特征之间的独立性，因为数据的特征之间不是相互独立的，每个特征之间都会存在一定的潜藏因素，如果贸然删除特征，就是导致数据之间的这层数据信息丢失掉。

这是PCA就发挥出了巨大的作用，他首先会将我们的数据维度降低，而且不会造成数据信息大幅度丢失，它是将我们的数据进行投影变换，讲过矩阵映射之后，使处理后的数据之间维度不在相关，也就是各个特征之间是相互独立的，这是就可以利用方差的大小进行选择特征，保留数据信息最多的列。

上图实验，我们将数据从4096维降到了50维，可以发现模型在训练集上的精度有了一定的提升，这说明我们的训练数据中存在一定噪音，会导致模型的过度拟合，当我们使用PCA降维后，这些噪音数据会被过滤掉，这时就会使训练集和测试集的分布一致，进而提高模型的精度，减小误差。



上图为我们使用的数据集，我们使用工具将该数据进行了可视化，由于没有指定色彩，这里是绿色的彩底



我们将数据进行PCA降维，下图横坐标代表数据进行PCA之后的维度，纵坐标是模型在测试集上的精度，这里我们可以发现数据在维度小于50的时候，随着特征数的增多，模型的精度越来越高，这说明维度越低，数据囊括的信息越少，也就导致模型的训练不足。

但是发现当数据特征在100维左右时，模型的精度随着维度的增加没有大幅度的提升，说明我们将数据降维到100维度正合适，模型性能提高了，而且精度也还不错

但是当达到270维左右，模型的精度有所下降，这就说明此时数据间出现了噪音，导致模型在训练期间同时将噪音也进行了训练，这就会导致降低模型的泛化性能。



